

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>PCA package &mdash; PCA-python  documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> PCA-python
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="user/PCA.html">Principal Component Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="user/clustering.html">Clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="user/cluster-biased-pca.html">Cluster-biased PCA</a></li>
<li class="toctree-l1"><a class="reference internal" href="user/train-test-select.html">Train and test data selection</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/train-test-selection.html">Selecting train and test data</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PCA-python</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>PCA package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/PCA.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="pca-package">
<h1>PCA package<a class="headerlink" href="#pca-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="PCA.manifold_dimensionality.html">PCA.manifold_dimensionality package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="PCA.manifold_dimensionality.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="PCA.manifold_dimensionality.html#module-PCA.manifold_dimensionality.normalized_local_variance">PCA.manifold_dimensionality.normalized_local_variance module</a></li>
<li class="toctree-l2"><a class="reference internal" href="PCA.manifold_dimensionality.html#module-PCA.manifold_dimensionality">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-PCA.PCA">
<span id="pca-pca-module"></span><h2>PCA.PCA module<a class="headerlink" href="#module-PCA.PCA" title="Permalink to this headline">¶</a></h2>
<dl class="py class">
<dt id="PCA.PCA.PCA">
<em class="property">class </em><code class="sig-prename descclassname">PCA.PCA.</code><code class="sig-name descname">PCA</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">scaling</span><span class="o">=</span><span class="default_value">'std'</span></em>, <em class="sig-param"><span class="n">neta</span><span class="o">=</span><span class="default_value">0</span></em>, <em class="sig-param"><span class="n">useXTXeig</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">nocenter</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class to support Principal Component Analysis</p>
<p class="rubric">Examples</p>
<p>pca = PCA(X)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – <p>matrix of data to apply PCA to. Variables are in columns and
observations are in rows.  Must have more observations than
variables.</p>
<p>NOTE: If a variable (column) is constant in the matrix X, an error will
arise telling the user to preprocess the data to remove that variable. The
preprocess class can do this for the user.</p>
</p></li>
<li><p><strong>scaling</strong> – (optional) default is ‘AUTO’
‘NONE’          no scaling
‘AUTO’ ‘STD’    scale by std
‘PARETO’        scale by std^2
‘VAST’          scale by std^2 / mean
‘VAST_2’        scale by std^2 * kurtosis^2 / mean
‘VAST_3’        scale by std^2 * kurtosis^2 / max
‘VAST_4’        scale by std^2 * kurtosis^2 / (max - min)
‘RANGE’         scale by (max-min)
‘LEVEL’         scale by mean
‘MAX’           scale by max value
‘POISSON’       scale by sqrt(mean)</p></li>
<li><p><strong>neta</strong> – (optional) number of retained eigenvalues - default is all</p></li>
<li><p><strong>useXTXeig</strong> – (optional) method for obtaining the eigenvalues (L) and eigenvectors (Q)
useXTXeig = False: uses singular-value decomposition (from scipy.linalg.svd)
useXTXeig = True (default): uses numpy.linalg.eigh on the covariance matrix (R)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="PCA.PCA.PCA.calculate_r2">
<code class="sig-name descname">calculate_r2</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.calculate_r2" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates R-squared values.</p>
<p>r2 = pca.calculate_r2( X )</p>
<p>Given the data used to construct the PCA, this calculates the R2 values
for the reduced representation of the data.  If all of the eigenvalues
are retained, then this should be unity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – data used to construct the PCA</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>R2 values for the reduced representation of the data (r2)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.convergence">
<code class="sig-name descname">convergence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">nmax</span></em>, <em class="sig-param"><span class="n">names</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">printwidth</span><span class="o">=</span><span class="default_value">10</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.convergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Print r2 values as a function of number of retained eigenvalues.</p>
<p>pca.convergence( X, nmax )
pca.convergence( X, nmax, names )</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – the original dataset</p></li>
<li><p><strong>nmax</strong> – the maximum number of PCs to consider</p></li>
<li><p><strong>names</strong> – (OPTIONAL) the names of the variables - otherwise variables are numbered</p></li>
<li><p><strong>printwidth</strong> – (OPTIONAL) width of columns printed out</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>[nmax,nvar] matrix containing the R^2 values for each variable as a
function of the number of retained eigenvalues.</p>
</dd>
</dl>
<p class="rubric">Example</p>
<p>pca.convergence(X,5) prints R^2 values retaining 1-5 eigenvalues</p>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.data_consistency_check">
<code class="sig-name descname">data_consistency_check</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">errorsAreFatal</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.data_consistency_check" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Checks if the supplied data matrix X is consistent with the PCA object</p>
<p>pca.data_consistency_check( X, errorsAreFatal )</p>
<dl class="field-list simple">
<dt class="field-odd">param X</dt>
<dd class="field-odd"><p>the independent variables</p>
</dd>
<dt class="field-even">param errorsAreFatal</dt>
<dd class="field-even"><p>(OPTIONAL) flag indicating if an error should be raised</p>
</dd>
</dl>
</div></blockquote>
<dl class="simple">
<dt>%                               if an incompatibility is detected - default is True</dt><dd><dl class="field-list simple">
<dt class="field-odd">return</dt>
<dd class="field-odd"><p>boolean for whether or not supplied data matrix X is consistent with the PCA object (okay)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.eig_bar_plot_maker">
<code class="sig-name descname">eig_bar_plot_maker</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">neig</span></em>, <em class="sig-param"><span class="n">DataName</span></em>, <em class="sig-param"><span class="n">barWidth</span><span class="o">=</span><span class="default_value">0.3</span></em>, <em class="sig-param"><span class="n">plotABS</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.eig_bar_plot_maker" title="Permalink to this definition">¶</a></dt>
<dd><p>Produces a bar plot of the weight of each state variable in the eigenvectors</p>
<p>pca.eig_bar_plot_maker( neig )</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>neig</strong> – Number of eigenvectors that you want to keep in the plot</p></li>
<li><p><strong>DataName</strong> – list containing the names of the variables</p></li>
<li><p><strong>barWidth</strong> – (OPTIONAL) width of each bar in the plot</p></li>
<li><p><strong>plotABS</strong> – (OPTIONAL) default False - plots the eigenvectors keeping their sign
if True - plots the absolute value of the eigenvectors</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(plot)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.eta2x">
<code class="sig-name descname">eta2x</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">eta</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.eta2x" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the principal components (or reconstructed variables)</p>
<p class="rubric">Example</p>
<p>eta = pca.eta2x(x) : calculate the principal components
xrec = pca.eta2x(eta) : calculate reconstructed variables</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>eta</strong> – the PCs</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the unscaled, uncentered approximation to the data (X)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.plot_convergence">
<code class="sig-name descname">plot_convergence</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">npc</span><span class="o">=</span><span class="default_value">0</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.plot_convergence" title="Permalink to this definition">¶</a></dt>
<dd><p>Plot the eigenvalues (bars) and the cumulative sum (line) to visualize the percent variance in the data
explained by each principal component individually and by each principal component cumulatively</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>npc</strong> – (OPTIONAL) how many principal components you want to visualize (default is all)</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(plot)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.principal_variables">
<code class="sig-name descname">principal_variables</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'B2'</span></em>, <em class="sig-param"><span class="n">x</span><span class="o">=</span><span class="default_value">[]</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.principal_variables" title="Permalink to this definition">¶</a></dt>
<dd><p>Extract principal variables from a PCA</p>
<p class="rubric">Example</p>
<p>ikeep = principal_variables()
ikeep = principal_variables(‘B4’)
ikeep = principal_variables(‘M2’, X )</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> – <dl class="simple">
<dt>[OPTIONAL] the method for determining the principal variables.</dt><dd><p>The following methods are currently supported:</p>
</dd>
<dt>”B4”<span class="classifier">selects principal variables based on the variables</span></dt><dd><p>contained in the eigenvectors corresponding to the
largest eigenvalues.</p>
</dd>
<dt>”B2”<span class="classifier">selects pvs based on variables contained in the smallest</span></dt><dd><p>eigenvalues.  These are discarded and the remaining
variables are used as the principal variables.  This is
the default method.</p>
</dd>
<dt>”M2”<span class="classifier">At each iteration, each remaining variable is analyzed</span></dt><dd><p>via PCA.  This is a very expensive method.</p>
</dd>
</dl>
</p></li>
<li><p><strong>x</strong> – [OPTIONAL] data arranged with observations in rows and
variables in columns.  Note that this is only required for the
“M2” method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a vector of indices of retained variables (ikeep)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.r2converge">
<code class="sig-name descname">r2converge</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">data</span></em>, <em class="sig-param"><span class="n">names</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">fname</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.r2converge" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Evaluate r2 values as a function of the number of retained eigenvalues.</p>
<dl class="simple">
<dt>Examples:</dt><dd><p>r2, neta = pca.r2converge( data )
r2, neta = pca.r2converge( data, names, ‘r2.csv’ )</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">param data</dt>
<dd class="field-odd"><p>the data to fit</p>
</dd>
<dt class="field-even">param names</dt>
<dd class="field-even"><p>[optional] names of the data</p>
</dd>
<dt class="field-odd">param fname</dt>
<dd class="field-odd"><p>[optional] file to output r2 information to</p>
</dd>
<dt class="field-even">return</dt>
<dd class="field-even"><p>r2 - [neta,nvar] The r2 values.  Each column is a different variable and</p>
</dd>
</dl>
</div></blockquote>
<p>%                     each row is for a different number of retained pcs.</p>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.set_retained_eigenvalues">
<code class="sig-name descname">set_retained_eigenvalues</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">method</span><span class="o">=</span><span class="default_value">'SCREE GRAPH'</span></em>, <em class="sig-param"><span class="n">option</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.set_retained_eigenvalues" title="Permalink to this definition">¶</a></dt>
<dd><p>Help determine how many eigenvalues to retain</p>
<p class="rubric">Example</p>
<p>pca = pca.set_retained_eigenvalues( method )</p>
<p>This function provides a few methods to select the number of eigenvalues
to be retained in the PCA reduction.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method</strong> – (optional) method to use in selecting retained eigenvalues.
Default is ‘SCREE GRAPH’</p></li>
<li><p><strong>option</strong> – (optional) if not supplied, information will be obtained
interactively.  Only used for the ‘TOTAL VARIANCE’ and
‘INDIVIDUAL VARIANCE’ methods.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the PCA object with the number of retained eigenvalues set on it. (pca)</p>
</dd>
</dl>
<p>The following methods are available:
‘TOTAL VARIANCE’      retain the eigenvalues needed to account for a</p>
<blockquote>
<div><p>specific percentage of the total variance (i.e.
80%). The required number of PCs is then the
smallest value of m for which this chosen
percentage is exceeded.</p>
</div></blockquote>
<dl class="simple">
<dt>‘INDIVIDUAL VARIANCE’ retain the components whose eigenvalues are</dt><dd><p>greater than the average of the eigenvalues
(Kaiser, 1960) or than 0.7 times he average of the
eigenvalues (Joliffe 1972). For a correlation
matrix this average equals 1.</p>
</dd>
<dt>‘BROKEN STICK’        select the retained PCs according to the</dt><dd><p>Broken Stick Model.</p>
</dd>
<dt>‘SCREE GRAPH’         use the scree graph, a plot of the eigenvalues</dt><dd><p>agaist their indexes, and look for a natural break
between the large and small eigenvalues.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.u_scores">
<code class="sig-name descname">u_scores</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.u_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the u scores (principal components)</p>
<p class="rubric">Example</p>
<p>uscores = pca.u_scores(X)</p>
<p>U-scores = obtained by using the U-vectors, i.e. the eigenvectors of the
covariance matrix S. The resulting U-scores are uncorrelated and have
variances equal to the corresponding eigenvalues.</p>
<p>This is entirely equivalent to x2eta.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – a set of observations of variables x (observations in rows),
unscaled, uncentered. These do not need to be the same
observations as were used to construct the PCA object. They
could be, e.g. functions of those variables.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>u scores or principal components (eta)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.w_scores">
<code class="sig-name descname">w_scores</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.w_scores" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculates the w scores</p>
<p class="rubric">Example</p>
<p>wscores = pca.w_scores( X )</p>
<p>W-scores = The U vectors are scaled by the inverse of the eigenvalues
square root, i.e. V = L^-0.5 * U. The W-scores are still uncorrelated and
have variances equal unity.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – a set of observations of variables x (observations in rows),
unscaled, uncentered. These do not need to be the same
observations as were used to construct the PCA object. They
could be, e.g. functions of those variables.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>u scores or principal components (eta)</p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>w scores</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.write_file_for_cpp">
<code class="sig-name descname">write_file_for_cpp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">filename</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.write_file_for_cpp" title="Permalink to this definition">¶</a></dt>
<dd><p>Writes the eigenvector matrix, centering and scaling vectors to .txt
for reading into C++</p>
<p class="rubric">Example</p>
<p>pca = PCA( x );
pca.wite2file(‘pcaData.txt’);</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>filename</strong> – path (including name of text file) for destination of data file</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(creates the .txt file in the destination specified by filename)</p>
</dd>
</dl>
<p>NOTE: This function writes only the eigenvector matrix, centering and
scaling factors - not all of the pca properties</p>
</dd></dl>

<dl class="py method">
<dt id="PCA.PCA.PCA.x2eta">
<code class="sig-name descname">x2eta</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">nocenter</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.PCA.x2eta" title="Permalink to this definition">¶</a></dt>
<dd><p>Calculate the principal components given the original data.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>X</strong> – a set of observations of variables x (observations in rows),
unscaled, uncentered. These do not need to be the same
observations as were used to construct the PCA object. They
could be, e.g. functions of those variables.</p>
</dd>
</dl>
<dl class="simple">
<dt>:param nocenter:[OPTIONAL] Defaults to centering. A nonzero argument here</dt><dd><p>will result in no centering being applied, even though it may
be present in the original PCA transformation. Use this
option only if you know what you are doing. PC source terms
are an example of where we want this to be flagged.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the principal components (eta)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt id="PCA.PCA.center_scale">
<code class="sig-prename descclassname">PCA.PCA.</code><code class="sig-name descname">center_scale</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">scaling</span></em>, <em class="sig-param"><span class="n">nocenter</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.center_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Centers and scales data - used in constructing PCA objects</p>
<p class="rubric">Example</p>
<p>xs = center_scale( X, opts )</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – uncentered, unscaled data</p></li>
<li><p><strong>scaling</strong> – the scaling methodology</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the centered and scaled data (Xout), the value for centering (xbar), the value for scaling (d)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="PCA.PCA.inv_center_scale">
<code class="sig-prename descclassname">PCA.PCA.</code><code class="sig-name descname">inv_center_scale</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em>, <em class="sig-param"><span class="n">xcenter</span></em>, <em class="sig-param"><span class="n">xscale</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.inv_center_scale" title="Permalink to this definition">¶</a></dt>
<dd><p>Invert whatever scaling and centering was done by center_scale</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> – the dataset you want to un-center and un-scale</p></li>
<li><p><strong>xcenter</strong> – the centering done on the original dataset X</p></li>
<li><p><strong>xscale</strong> – the scaling done on the original dataset X</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the unmanipulated/original dataset (X)</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="PCA.PCA.preprocess">
<em class="property">class </em><code class="sig-prename descclassname">PCA.PCA.</code><code class="sig-name descname">preprocess</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.preprocess" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>class for preprocessing data which will check for the constant values and remove them, saving whatever manipulations
were done so a user can manipulate new data in the same way</p>
<p>Could make more complicated ones as needed</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.PCA.remove_constant_vars">
<code class="sig-prename descclassname">PCA.PCA.</code><code class="sig-name descname">remove_constant_vars</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">maxtol</span><span class="o">=</span><span class="default_value">1e-12</span></em>, <em class="sig-param"><span class="n">rangetol</span><span class="o">=</span><span class="default_value">0.0001</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.remove_constant_vars" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove any constant variables (columns) in the data X
Specifically preprocessing for PCA so the eigenvalue calculation doesn’t break</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – original data</p></li>
<li><p><strong>maxtol</strong> – tolerance for the maximum absolute value of a column (variable) in X to be saved</p></li>
<li><p><strong>rangetol</strong> – tolerance for the range (max-min) over the maximum absolute value of a column (variable) in X to
be saved</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the manipulated data (manipulated), the indices of columns removed from X (idx_removed), the original
data X (original), the indices of columns retained in X (idx_retained)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="PCA.PCA.test">
<code class="sig-prename descclassname">PCA.PCA.</code><code class="sig-name descname">test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#PCA.PCA.test" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs regression testing of the PCA class</p>
<p>Testing (with no scaling) that PCA calculates the same mean that is added to a dataset with zero mean
and returns the same Q and L from svd on the dataset with zero mean</p>
<p>Then testing if feed already transformed eta’s to PCA, will return same eta’s when do x2eta</p>
<p class="rubric">Examples</p>
<p>result = PCA.test()  -&gt; run tests</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Boolean for whether tests passed or not</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pca-cluster-biased-pca-module">
<h2>PCA.cluster_biased_pca module<a class="headerlink" href="#pca-cluster-biased-pca-module" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-PCA.clustering">
<span id="pca-clustering-module"></span><h2>PCA.clustering module<a class="headerlink" href="#module-PCA.clustering" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="PCA.clustering.degrade_clusters">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">degrade_clusters</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.degrade_clusters" title="Permalink to this definition">¶</a></dt>
<dd><p>This function renumerates clusters if either of these two cases is true:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">idx</span></code> is composed of non-consecutive integers, or</p></li>
<li><p>the smallest cluster number in <code class="docutils literal notranslate"><span class="pre">idx</span></code> is not equal to <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
</ul>
<p><strong>Example:</strong></p>
<p>Starting with an <code class="docutils literal notranslate"><span class="pre">idx</span></code> that is the following:
<code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">2,</span> <span class="pre">0,</span> <span class="pre">5,</span> <span class="pre">10]</span></code> this function turns this <code class="docutils literal notranslate"><span class="pre">idx</span></code> to:
<code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">0,</span> <span class="pre">2,</span> <span class="pre">3]</span></code>, where clusters are numbered with consecutive integers.</p>
<p>Alternatively, if <code class="docutils literal notranslate"><span class="pre">idx</span></code> is: <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">3]</span></code> this function turns
this <code class="docutils literal notranslate"><span class="pre">idx</span></code> to: <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">2]</span></code> so that the smallest cluster number
is equal to <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idx</strong> – raw vector of indices classifying observations to clusters.</p></li>
<li><p><strong>verbose</strong> – boolean for printing clustering details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">idx_degraded</span></code> degraded vector of indices classifying observations to
clusters. The first cluster has index 0.
<code class="docutils literal notranslate"><span class="pre">k_update</span></code> the updated number of clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.flip_clusters">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">flip_clusters</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">dictionary</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.flip_clusters" title="Permalink to this definition">¶</a></dt>
<dd><p>This function flips the cluster labelling according to instructions provided
in the dictionary. For a <code class="docutils literal notranslate"><span class="pre">dictionary</span> <span class="pre">=</span> <span class="pre">{key</span> <span class="pre">:</span> <span class="pre">value}</span></code>, a cluster with a
number <code class="docutils literal notranslate"><span class="pre">key</span></code> will get a number <code class="docutils literal notranslate"><span class="pre">value</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idx</strong> – vector of indices classifying observations to clusters.
The first cluster has index 0.</p></li>
<li><p><strong>dictionary</strong> – a dictionary specifying the cluster numeration flipping instructions.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">flipped_idx</span></code> vector of indices classifying observations to clusters.
The first cluster has index 0.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.get_centroids">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">get_centroids</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">idx</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.get_centroids" title="Permalink to this definition">¶</a></dt>
<dd><p>This function computes the centroids for the clustering specified in the
<code class="docutils literal notranslate"><span class="pre">idx</span></code> vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – data set for computing the cluster centroids.</p></li>
<li><p><strong>idx</strong> – vector of indices classifying observations to clusters.
The first cluster has index 0.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">centroids</span></code> matrix of cluster centroids. It has size <code class="docutils literal notranslate"><span class="pre">k</span></code> times number of
observations.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.get_partition">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">get_partition</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.get_partition" title="Permalink to this definition">¶</a></dt>
<dd><p>This function performs partitioning of the data set observations according
to <code class="docutils literal notranslate"><span class="pre">idx</span></code> provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – data set to partition.</p></li>
<li><p><strong>idx</strong> – vector of indices classifying observations to clusters.
The first cluster has index 0.</p></li>
<li><p><strong>verbose</strong> – boolean for printing details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">data_in_clusters</span></code> list of <code class="docutils literal notranslate"><span class="pre">k_new</span></code> arrays that contains original data
set observations in each cluster.
<code class="docutils literal notranslate"><span class="pre">data_idx_in_clusters</span></code> list of <code class="docutils literal notranslate"><span class="pre">k_new</span></code> arrays that contains indices of
the original data set observations in each cluster.
<code class="docutils literal notranslate"><span class="pre">k_new</span></code> the updated number of clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.get_populations">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">get_populations</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.get_populations" title="Permalink to this definition">¶</a></dt>
<dd><p>This function computes populations (number of observations) in clusters
specified in the <code class="docutils literal notranslate"><span class="pre">idx</span></code> vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>idx</strong> – vector of indices classifying observations to clusters.
The first cluster has index 0.</p></li>
<li><p><strong>verbose</strong> – boolean for printing details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">populations</span></code> list of cluster populations. Each entry referes to one cluster
ordered according to <code class="docutils literal notranslate"><span class="pre">idx</span></code>.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.kmeans">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">kmeans</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">k</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.kmeans" title="Permalink to this definition">¶</a></dt>
<dd><p>This function performs K-Means clustering.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – conditioning variable or a data set.</p></li>
<li><p><strong>k</strong> – number of clusters to partition the data.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">idx</span></code> vector of indices classifying observations to clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.mixture_fraction_bins">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">mixture_fraction_bins</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">Z</span></em>, <em class="sig-param"><span class="n">k</span></em>, <em class="sig-param"><span class="n">Z_stoich</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.mixture_fraction_bins" title="Permalink to this definition">¶</a></dt>
<dd><p>This function does clustering based on dividing a mixture fraction vector
<code class="docutils literal notranslate"><span class="pre">Z</span></code> into bins of equal lengths. The vector is first split to lean and rich
side and then the sides get divided further into clusters. When <code class="docutils literal notranslate"><span class="pre">k</span></code> is even,
this function will always create equal number of clusters on the lean and
rich side. When <code class="docutils literal notranslate"><span class="pre">k</span></code> is odd, there will be one more cluster on the rich side
compared to the lean side.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>Z</strong> – vector of mixture fraction values.</p></li>
<li><p><strong>k</strong> – number of clusters to partition the data.</p></li>
<li><p><strong>Z_stoich</strong> – stoichiometric mixture fraction.</p></li>
<li><p><strong>verbose</strong> – (optional)
boolean for printing clustering details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<cite>idx</cite> vector of indices classifying observations to clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.pc_source_bins">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">pc_source_bins</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pc_source</span></em>, <em class="sig-param"><span class="n">k</span></em>, <em class="sig-param"><span class="n">zero_offset_percentage</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">split_at_zero</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.pc_source_bins" title="Permalink to this definition">¶</a></dt>
<dd><p>This function does clustering based on bins of a PC-source vector
<code class="docutils literal notranslate"><span class="pre">pc_source</span></code>. By default, it finds one cluster between a negative and
a positive offset from PC-source=0. The offset is computed from the input
parameter <code class="docutils literal notranslate"><span class="pre">zero_offset_percentage</span></code> which specifies a percentage of the range
<code class="docutils literal notranslate"><span class="pre">pc_source_max</span> <span class="pre">-</span> <span class="pre">pc_source_min</span></code>. Further clusters are found by clustering
positive and negative PC-sources alternatingly into bins of equal lengths.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">split_at_zero</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the partitioning will always find one
cluster that is between <code class="docutils literal notranslate"><span class="pre">-offset</span></code> and 0 and another cluster that is between
0 and <code class="docutils literal notranslate"><span class="pre">+offset</span></code>.</p>
<p>Due to the nature of this clustering technique, the smallest allowed number
of clusters is 3 if <code class="docutils literal notranslate"><span class="pre">split_at_zero=False</span></code>. This is to assure that there are
at least there three clusters: with high negative values, with close to zero
values, with high positive values.</p>
<p>If <code class="docutils literal notranslate"><span class="pre">split_at_zero=True</span></code>, the smallest allowed number of clusters is 4. This
is to assure that there are at least four clusters: with high negative
values, with negative values close to zero, with positive values close to
zero and with high positive values.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pc_source</strong> – vector of variable values.</p></li>
<li><p><strong>k</strong> – number of clusters to partition the data.
Cannot be smaller than 3 if <code class="docutils literal notranslate"><span class="pre">split_at_zero=False</span></code> or smaller
than 4 if <code class="docutils literal notranslate"><span class="pre">split_at_zero=True</span></code>.</p></li>
<li><p><strong>zero_offset_percentage</strong> – (optional)
percentage of <code class="docutils literal notranslate"><span class="pre">|pc_source_max</span> <span class="pre">-</span> <span class="pre">pc_source_min|</span></code> to take as the
<code class="docutils literal notranslate"><span class="pre">offset</span></code> value.</p></li>
<li><p><strong>split_at_zero</strong> – (optional)
boolean specifying whether partitioning should be done at PC-source=0.</p></li>
<li><p><strong>verbose</strong> – (optional)
boolean for printing clustering details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">idx</span></code> vector of indices classifying observations to clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.predefined_variable_bins">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">predefined_variable_bins</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">var</span></em>, <em class="sig-param"><span class="n">split_values</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.predefined_variable_bins" title="Permalink to this definition">¶</a></dt>
<dd><p>This function does clustering based on dividing a variable vector <code class="docutils literal notranslate"><span class="pre">var</span></code> into
bins such that the split is done at values specified in the <code class="docutils literal notranslate"><span class="pre">split_values</span></code>
list.</p>
<p><em>Note:</em> When a split is performed at a given <code class="docutils literal notranslate"><span class="pre">value_i</span></code>, the observation in <code class="docutils literal notranslate"><span class="pre">var</span></code>
that takes exactly that value is assigned to the newly created bin.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>var</strong> – vector of variable values.</p></li>
<li><p><strong>split_values</strong> – list containing values at which the split to bins should be performed.</p></li>
<li><p><strong>verbose</strong> – (optional)
boolean for printing clustering details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">idx</span></code> vector of indices classifying observations to clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.test">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.test" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tests the <code class="docutils literal notranslate"><span class="pre">clustering</span></code> module.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.variable_bins">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">variable_bins</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">var</span></em>, <em class="sig-param"><span class="n">k</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.variable_bins" title="Permalink to this definition">¶</a></dt>
<dd><p>This function does clustering based on dividing a variable vector <code class="docutils literal notranslate"><span class="pre">var</span></code> into
bins of equal lengths.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>var</strong> – vector of variable values.</p></li>
<li><p><strong>k</strong> – number of clusters to partition the data.</p></li>
<li><p><strong>verbose</strong> – (optional)
boolean for printing clustering details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">idx</span></code> vector of indices classifying observations to clusters.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.clustering.vqpca">
<code class="sig-prename descclassname">PCA.clustering.</code><code class="sig-name descname">vqpca</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">k</span></em>, <em class="sig-param"><span class="n">n_pcs</span></em>, <em class="sig-param"><span class="n">scaling_criteria</span></em>, <em class="sig-param"><span class="n">idx_0</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">maximum_number_of_iterations</span><span class="o">=</span><span class="default_value">1000</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.clustering.vqpca" title="Permalink to this definition">¶</a></dt>
<dd><p>This function performs Vector Quantization clustering using
Principal Component Analysis.</p>
<p><strong>Note:</strong>
VQPCA algorithm will center the global data set <code class="docutils literal notranslate"><span class="pre">X</span></code> by mean and scale by
the scaling specified in the <code class="docutils literal notranslate"><span class="pre">scaling_criteria</span></code> parameter. Data in local
clusters will be centered by the mean but will not be scaled.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> – raw global data set, uncentered and unscaled.</p></li>
<li><p><strong>k</strong> – (optional)
number of clusters to partition the data.</p></li>
<li><p><strong>n_pcs</strong> – (optional)
number of Principal Components (PCs) that will be used to reconstruct the data
at each iteration.</p></li>
<li><p><strong>scaling_criteria</strong> – (optional)
scaling critertion for the global data set.</p></li>
<li><p><strong>idx_0</strong> – (optional)
user-supplied initial <code class="docutils literal notranslate"><span class="pre">idx</span></code> for initializing the centroids. By default
random intialization is performed.</p></li>
<li><p><strong>maximum_number_of_iterations</strong> – (optional)
the maximum number of iterations that the algorithm will loop through.</p></li>
<li><p><strong>verbose</strong> – (optional)
boolean for printing clustering details.</p></li>
</ul>
</dd>
</dl>
<p><strong>Returns:</strong>
<code class="docutils literal notranslate"><span class="pre">idx</span></code> vector of indices classifying observations to clusters.</p>
</dd></dl>

</div>
<div class="section" id="module-PCA.train_test_select">
<span id="pca-train-test-select-module"></span><h2>PCA.train_test_select module<a class="headerlink" href="#module-PCA.train_test_select" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="PCA.train_test_select.test">
<code class="sig-prename descclassname">PCA.train_test_select.</code><code class="sig-name descname">test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#PCA.train_test_select.test" title="Permalink to this definition">¶</a></dt>
<dd><p>This function tests the <cite>training_data_generation</cite> module.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.train_test_select.train_test_split_fixed_number_from_idx">
<code class="sig-prename descclassname">PCA.train_test_select.</code><code class="sig-name descname">train_test_split_fixed_number_from_idx</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">perc</span></em>, <em class="sig-param"><span class="n">test_selection_option</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.train_test_select.train_test_split_fixed_number_from_idx" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes an <cite>idx</cite> classifications from a clustering technique and
samples a fixed number <cite>n_of_samples</cite> of observations from every cluster as
training data.</p>
<p><cite>n_of_samples</cite> is estimated based on the percentage provided. First, the
total number of samples for training is estimated as a percentage <cite>perc</cite>
from the total number of observations <cite>n_obs</cite>. Next, this number is devided
equally into <cite>k</cite> clusters.</p>
<p>There is a bar that no more than 50% of observations from any cluster will
be taken for training. This is to avoid that too little samples will remain
for test data from small clusters.</p>
<p>Test data is then drawn from every cluster equally in a similar way, in a
quantity equal to the number of remaining samples from the smallest cluster.</p>
<p>If the full data has 10 observations with indices:</p>
<p><cite>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</cite></p>
<p>and a clustering technique divided the observations into clusters in the
following way:</p>
<p><cite>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]</cite></p>
<p>Then, if you request 40% of the data for training, the function may return:</p>
<p><cite>idx_train = [0, 1, 7, 9]</cite></p>
<p>as the training data (where observations 0 and 1 belong to the first cluster
and observations 7 and 9 belong to the second cluster).</p>
<p>Test data may then become:</p>
<p><cite>idx_test = [3, 5, 6, 8]</cite></p>
<p>Two options for sampling test data are implemented. If you select
<cite>test_selection_option=1</cite>, all remaining samples that were not taken as
training data become the test data. If you select <cite>test_selection_option=2</cite>,
the smallest cluster is found and the remaining number of observations are
taken as test data in that cluster. Next, the same number of observations is
taken from all remaining larger clusters.</p>
<dl class="simple">
<dt><cite>idx</cite>         - vector of indices classifying observations to clusters.</dt><dd><p>The first cluster has index 0.</p>
</dd>
<dt><cite>perc</cite>        - percentage of data to be selected as training data from each</dt><dd><p>cluster. Set perc=20 if you want 20%.</p>
</dd>
<dt><cite>test_selection_option</cite></dt><dd><ul class="simple">
<li><p>select 1 if you want all remaining samples to become test
data. Select 2 if you want the same number of samples from
each cluster to become test data.</p></li>
</ul>
</dd>
</dl>
<p><cite>verbose</cite>     - boolean for printing clustering details.</p>
<p><cite>idx_train</cite>   - indices of the training data.
<cite>idx_test</cite>    - indices of the test data.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.train_test_select.train_test_split_manual_from_idx">
<code class="sig-prename descclassname">PCA.train_test_select.</code><code class="sig-name descname">train_test_split_manual_from_idx</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">sampling_dictionary</span></em>, <em class="sig-param"><span class="n">sampling_type</span><span class="o">=</span><span class="default_value">'percentage'</span></em>, <em class="sig-param"><span class="n">bar50</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.train_test_select.train_test_split_manual_from_idx" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes an <cite>idx</cite> classifications from a clustering technique and
a dictionary <cite>sampling_dictionary</cite> in which you manually specify what
perecentage or what number of samples should be taken from every cluster as
the training data.</p>
<p>By default, there is a bar that no more than 50% of observations from any
cluster will be taken for training. This is to avoid that too little samples
will remain for test data from small clusters. If the parameter <cite>bar50</cite> is
set to False, this function will allow to sample more than 50% of
observations.</p>
<div class="line-block">
<div class="line">Note that this function does not <cite>degrade_clusters</cite> to avoid disambiguity</div>
<div class="line">between cluster numeration inside <cite>idx</cite> and inside the keys of the</div>
<div class="line"><cite>sampling_dictionary</cite>! It will however check whether keys are consistent</div>
<div class="line">with <cite>idx</cite> entries and if yes it will continue running. If the <cite>idx</cite></div>
<div class="line">requires running <cite>degrade_clusters</cite>, information will be printed.</div>
</div>
<p>If the full data has 10 observations with indices:</p>
<p><cite>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</cite></p>
<p>and a clustering technique divided the observations into clusters in the
following way:</p>
<p><cite>[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]</cite></p>
<p>and the dictionary is: <cite>sampling_dictionary = {0:3, 1:1}</cite> with the values
representing a ‘number’, the function may return:</p>
<p><cite>idx_train = [2, 3, 5, 9]</cite></p>
<p>so that 3 samples are taken from the first cluster and 1 sample is taken
from the second cluster.</p>
<dl class="simple">
<dt><cite>idx</cite>         - vector of indices classifying observations to clusters.</dt><dd><p>The first cluster has index 0.</p>
</dd>
<dt><cite>sampling_dictionary</cite></dt><dd><ul class="simple">
<li><p>dictionary specifying manual sampling. Keys are cluster
numbers and values are either ‘percentage’ or ‘number’ of
samples to be taken from that cluster. Keys should match the
cluster numbering as per <cite>idx</cite>.</p></li>
</ul>
</dd>
<dt><cite>sampling_type</cite></dt><dd><ul class="simple">
<li><p>string specifying whether percentage or number is given in
the <cite>sampling_dictionary</cite>. Available options: ‘percentage’
or ‘number’. The default is ‘percentage’.</p></li>
</ul>
</dd>
</dl>
<p><cite>bar50</cite>       - boolean specifying whether the 50% bar should apply.
<cite>verbose</cite>     - boolean for printing clustering details.</p>
<p><cite>idx_train</cite>   - indices of the training data.
<cite>idx_test</cite>    - indices of the test data.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.train_test_select.train_test_split_percentage_from_idx">
<code class="sig-prename descclassname">PCA.train_test_select.</code><code class="sig-name descname">train_test_split_percentage_from_idx</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">idx</span></em>, <em class="sig-param"><span class="n">perc</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.train_test_select.train_test_split_percentage_from_idx" title="Permalink to this definition">¶</a></dt>
<dd><p>This function takes an <cite>idx</cite> classifications from a clustering technique and
samples a certain percentage <cite>perc</cite> from every cluster as the training data.
The remaining percentage is the test data.</p>
<p>If the full data has 10 observations with indices:</p>
<p><cite>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</cite></p>
<p>and you requested 40% of the data to be training data, the function may
return:</p>
<p><cite>idx_train = [0, 1, 2, 7]</cite></p>
<p>and:</p>
<p><cite>idx_test = [3, 4, 5, 6, 8, 9]</cite></p>
<p>as the remaining 60% test data.</p>
<dl class="simple">
<dt><cite>idx</cite>         - vector of indices classifying observations to clusters.</dt><dd><p>The first cluster has index 0.</p>
</dd>
<dt><cite>perc</cite>        - percentage of data to be selected as training data from each</dt><dd><p>cluster. Set perc=20 if you want 20%.</p>
</dd>
</dl>
<p><cite>verbose</cite>     - boolean for printing clustering details.</p>
<p><cite>idx_train</cite>   - indices of the training data.
<cite>idx_test</cite>    - indices of the test data.</p>
</dd></dl>

<dl class="py function">
<dt id="PCA.train_test_select.train_test_split_random">
<code class="sig-prename descclassname">PCA.train_test_select.</code><code class="sig-name descname">train_test_split_random</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_obs</span></em>, <em class="sig-param"><span class="n">perc</span></em>, <em class="sig-param"><span class="n">idx_test</span><span class="o">=</span><span class="default_value">[]</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span><a class="headerlink" href="#PCA.train_test_select.train_test_split_random" title="Permalink to this definition">¶</a></dt>
<dd><p>This function splits dataset into training and testing using random sampling.</p>
<p>If the full data has 10 observations whose indices are:</p>
<p><cite>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]</cite></p>
<p>and you request 40% of the data to be training data, the function may return:</p>
<p><cite>idx_train = [0, 1, 2, 7]</cite></p>
<p>and:</p>
<p><cite>idx_test = [3, 4, 5, 6, 8, 9]</cite></p>
<p>as the remaining 60% test data.</p>
<p><cite>n_obs</cite>       - number of observations in the original data set.
<cite>perc</cite>        - percentage of data to be selected as training data from each</p>
<blockquote>
<div><p>cluster. Set perc=20 if you want 20%.</p>
</div></blockquote>
<dl class="simple">
<dt><cite>idx_test</cite>    - are the user-provided indices for test data. If specified,</dt><dd><p>the training data will be selected ignoring the indices in
<cite>idx_test</cite> and the test data will be returned the same as
the user-provided <cite>idx_test</cite>.
If not specified, all remaining samples become test data.</p>
</dd>
</dl>
<p><cite>verbose</cite>     - boolean for printing clustering details.</p>
<p><cite>idx_train</cite>   - indices of the training data.
<cite>idx_test</cite>    - indices of the test data.</p>
</dd></dl>

</div>
<div class="section" id="module-PCA">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-PCA" title="Permalink to this headline">¶</a></h2>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Elizabeth Armstrong, Kamila Zdybal

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>