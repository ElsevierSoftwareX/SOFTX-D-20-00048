{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='header'></a>\n",
    "# Handling source terms\n",
    "\n",
    "This tutorial can be of interest to researchers working with reactive flows data sets. We present how source terms of the original state variables can be handled using **PCAfold** software. Specifically, **PCAfold** functionalities accommodate treatment of sources of Principal Components which can be valuable for implementing PC-transport approaches such as proposed in [1].\n",
    "\n",
    "A data set representing combustion of syngas in air generated from steady laminar flamelet model using [*Spitfire*](https://github.com/sandialabs/Spitfire) software [1] and a chemical mechanism by Hawkes et al. [2] is used as a demo data set. \n",
    "\n",
    "> [1] James C. Sutherland and Alessandro Parente. *Combustion modeling using principal component analysis.* Proceedings of the Combustion Institute, 32(1):1563–1570, 2009.\n",
    "> \n",
    "> [2] [M. A. Hansen - *Spitfire*, 2020](https://github.com/sandialabs/Spitfire)\n",
    "> \n",
    "> [3] E. R. Hawkes, R. Sankaran, J. C. Sutherland, J. H. Chen - *Scalar mixing in direct numerical simulations of temporally evolving plane jet flames with skeletal co/h2 kinetics*, Proceedings of the combustion institute 31 (1) (2007) 1633–1640\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PCAfold import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a demo data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original variables:\n",
    "X = np.genfromtxt('data-state-space.csv', delimiter=',')\n",
    "\n",
    "# Corresponding source terms of the original variables:\n",
    "S_X = np.genfromtxt('data-state-space-sources.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform PCA on the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X = PCA(X, scaling='auto', n_components=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the original data set to the newly identified basis and compute the Principal Components (PCs) $\\mathbf{Z}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = pca_X.transform(X, nocenter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the source terms to the newly identified basis and compute the sources of Principal Components $\\mathbf{S_Z}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_Z = pca_X.transform(S_X, nocenter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we set the flag ``nocenter=True`` which is a specific setting that should be applied when transforming source terms. With that setting, only scales will be applied when transforming $\\mathbf{S_X}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
